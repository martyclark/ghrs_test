# -*- coding: utf-8 -*-
"""ghslHeat.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1OZ7p7rAUtRfKEWaa-6CGj2eR_pmy79SZ

Mount drive
"""

from google.colab import drive
drive.mount('/content/drive')

"""Apply join using pandas"""

import pandas as pd

# Replace with the actual path to your files in Google Drive or your local directory
ghs_stat_file_path = '/content/drive/MyDrive/GEOSec/hackathon/GHS_STAT.csv'
combined_file_path = '/content/drive/MyDrive/GEOSec/hackathon/WBGT_combined.csv'

# Read the CSV files into Pandas DataFrames
ghs_stat_df = pd.read_csv(ghs_stat_file_path, encoding='ISO-8859-1')
combined_df = pd.read_csv(combined_file_path)

"""Find duplicates"""

# Find duplicates in GHS_STAT
duplicate_ids_ghs_stat = ghs_stat_df[ghs_stat_df.duplicated(subset=['ID_HDC_G0'], keep=False)]['ID_HDC_G0']
if not duplicate_ids_ghs_stat.empty:
    print("Duplicate ID_HDC_G0 values found in GHS_STAT:")
    print(duplicate_ids_ghs_stat.tolist())  # Convert to list and print

# Find duplicates in combined
duplicate_ids_combined = combined_df[combined_df.duplicated(subset=['ID_HDC_G0'], keep=False)]['ID_HDC_G0']
if not duplicate_ids_combined.empty:
    print("\nDuplicate ID_HDC_G0 values found in combined:")
    print(duplicate_ids_combined.tolist())  # Convert to list and print

# Convert ID_HDC_G0 to the same datatype in both DataFrames
ghs_stat_df['ID_HDC_G0'] = ghs_stat_df['ID_HDC_G0'].astype(str)
combined_df['ID_HDC_G0'] = combined_df['ID_HDC_G0'].astype(str)


# Count unique values and compare to total rows
unique_ghs_ids = ghs_stat_df['ID_HDC_G0'].nunique()
total_rows_ghs = len(ghs_stat_df)
if unique_ghs_ids != total_rows_ghs:
    print(f"GHS_STAT has {total_rows_ghs - unique_ghs_ids} duplicates in ID_HDC_G0")

unique_combined_ids = combined_df['ID_HDC_G0'].nunique()
total_rows_combined = len(combined_df)
if unique_combined_ids != total_rows_combined:
    print(f"combined has {total_rows_combined - unique_combined_ids} duplicates in ID_HDC_G0")

# Sample 100 rows from each DataFrame
sample_ghs = ghs_stat_df.sample(100)
sample_combined = combined_df.sample(100)

# Merge the samples
sample_merged = pd.merge(sample_ghs, sample_combined, on="ID_HDC_G0", how="inner")

print(sample_merged.shape)  # Print the dimensions of the sample merge

# Remove rows with NA values in ID_HDC_G0 for both DataFrames
ghs_stat_df = ghs_stat_df.dropna(subset=['ID_HDC_G0'])
combined_df = combined_df.dropna(subset=['ID_HDC_G0'])

# Convert ID_HDC_G0 to numeric, coercing non-numeric to NaN
ghs_stat_df['ID_HDC_G0'] = pd.to_numeric(ghs_stat_df['ID_HDC_G0'], errors='coerce')
combined_df['ID_HDC_G0'] = pd.to_numeric(combined_df['ID_HDC_G0'], errors='coerce')

# Remove rows with NaN values in ID_HDC_G0
ghs_stat_df.dropna(subset=['ID_HDC_G0'], inplace=True)
combined_df.dropna(subset=['ID_HDC_G0'], inplace=True)

# Find duplicates in GHS_STAT (after removing NAs)
duplicate_ids_ghs_stat = ghs_stat_df[ghs_stat_df.duplicated(subset=['ID_HDC_G0'], keep=False)]['ID_HDC_G0']
if not duplicate_ids_ghs_stat.empty:
    print("Duplicate ID_HDC_G0 values found in GHS_STAT (after removing NAs):")
    print(duplicate_ids_ghs_stat.tolist())

# Find duplicates in combined (after removing NAs)
duplicate_ids_combined = combined_df[combined_df.duplicated(subset=['ID_HDC_G0'], keep=False)]['ID_HDC_G0']
if not duplicate_ids_combined.empty:
    print("\nDuplicate ID_HDC_G0 values found in combined (after removing NAs):")
    print(duplicate_ids_combined.tolist())

# Check for and handle duplicate IDs (optional, based on your needs)
if ghs_stat_df['ID_HDC_G0'].duplicated().any():
    print("Warning: Duplicates found in GHS_STAT['ID_HDC_G0']")
    # Choose how to handle duplicates: drop them, aggregate, etc.
if combined_df['ID_HDC_G0'].duplicated().any():
    print("Warning: Duplicates found in combined['ID_HDC_G0']")
    # Choose how to handle duplicates

# Now proceed with your merge...
merged_data = pd.merge(ghs_stat_df, combined_df, on="ID_HDC_G0", how="inner")

# Save the merged DataFrame to a new CSV file
merged_data.to_csv("merged_heatData.csv", index=False)

# Display the first few rows of the merged data (optional)
print(merged_data.head().to_markdown(index=False, numalign="left", stralign="left"))

"""Now visualise the data with Kepler.gl"""

#install kepler
!pip install keplergl

#import kepler library
from keplergl import KeplerGl

from google.colab import output
output.enable_custom_widget_manager()

#identify coordinate columns
print(merged_data.columns)

#import pandas and pass the joined dataframe
import geopandas as gpd
merged_data_gdf = gpd.GeoDataFrame(
    merged_data, geometry=gpd.points_from_xy(merged_data.GCPNT_LON, merged_data.GCPNT_LAT)
)

# Remove original lat/lon columns
# merged_data_gdf = merged_data_gdf.drop(columns=['GCPNT_LAT', 'GCPNT_LON'])

#Create a KeplerGl object and pass your GeoDataFrame to it:
map_1 = KeplerGl(height=400)
map_1.add_data(data=merged_data_gdf, name='merged_data')

"""Support for third party widgets will remain active for the duration of the session. To disable support:"""


# Explicitly set the layer type and configuration
config = {
  "version": "v1",
  "config": {
    "visState": {
      "filters": [],
      "layers": [
        {
          "id": "1eajwc8",
          "type": "point",
          "config": {
            "dataId": "merged_data",
            "label": "Days Over 30.5Â°C",
            "color": [
              18,
              147,
              154
            ],
            "highlightColor": [
              252,
              242,
              26,
              255
            ],
            "columns": {
              "lat": "GCPNT_LAT",
              "lng": "GCPNT_LON",
              "altitude": None
            },
            "isVisible": True,
            "visConfig": {
              "radius": 10,
              "fixedRadius": False,
              "opacity": 0.8,
              "outline": False,
              "thickness": 2,
              "strokeColor": [
                255,
                0,
                0
              ],
              "colorRange": {
                "name": "Global Warming 5",
                "type": "sequential",
                "category": "Uber",
                "colors": [
                  "#FFC300",
                  "#D55D0E",
                  "#AC1C17",
                  "#831A3D",
                  "#5A1846"
                ],
                "reversed": True
              },
              "strokeColorRange": {
                "name": "Global Warming",
                "type": "sequential",
                "category": "Uber",
                "colors": [
                  "#5A1846",
                  "#900C3F",
                  "#C70039",
                  "#E3611C",
                  "#F1920E",
                  "#FFC300"
                ]
              },
              "radiusRange": [
                0,
                50
              ],
              "filled": True
            },
            "hidden": False,
            "textLabel": [
              {
                "field": None,
                "color": [
                  255,
                  255,
                  255
                ],
                "size": 18,
                "offset": [
                  0,
                  0
                ],
                "anchor": "start",
                "alignment": "center"
              }
            ]
          },
          "visualChannels": {
            "colorField": {
              "name": "days over 30.5 degC - CarbonPlan - historical",
              "type": "real"
            },
            "colorScale": "quantize",
            "strokeColorField": None,
            "strokeColorScale": "quantile",
            "sizeField": None,
            "sizeScale": "linear"
          }
        }
      ],
      "interactionConfig": {
        "tooltip": {
          "fieldsToShow": {
            "merged_data": [
              {
                "name": "UC_NM_MN",
                "format": None
              },
              {
                "name": "days over 30.5 degC - CarbonPlan - historical",
                "format": None
              }
            ]
          },
          "compareMode": False,
          "compareType": "absolute",
          "enabled": True
        },
        "brush": {
          "size": 0.5,
          "enabled": False
        },
        "geocoder": {
          "enabled": False
        },
        "coordinate": {
          "enabled": False
        }
      },
      "layerBlending": "normal",
      "splitMaps": [],
      "animationConfig": {
        "currentTime": None,
        "speed": 1
      }
    },
    "mapState": {
      "bearing": 0,
      "dragRotate": False,
      "latitude": 18.84983471406084,
      "longitude": 63.637463259199514,
      "pitch": 0,
      "zoom": 1.5541232428943326,
      "isSplit": False
    },
    "mapStyle": {
      "styleType": "dark",
      "topLayerGroups": {},
      "visibleLayerGroups": {
        "label": True,
        "road": True,
        "border": False,
        "building": True,
        "water": True,
        "land": True,
        "3d building": False
      },
      "threeDBuildingColor": [
        9.665468314072013,
        17.18305478057247,
        31.1442867897876
      ],
      "mapStyles": {}
    }
  }
}

# Create Kepler.gl map
map_1 = KeplerGl(height=400, config=config)

#add data
map_1.add_data(data=merged_data_gdf, name='merged_data')

#update config?
map_1.config = config  # Set the updated configuration

#print the config to check the correct keys are present
#print(map_1.config)

#import json

#with open('your_config_filename.json', 'w') as outfile:
#    json.dump(map_1.config, outfile)

#print(merged_data_gdf.columns)

#print(merged_data_gdf.geometry.type)

# Display the map

map_1

print(map_1.config)

merged_data_gdf.info()

from google.colab import output
output.disable_custom_widget_manager()